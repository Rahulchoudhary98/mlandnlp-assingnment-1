{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae0f54e-ec2f-49df-93fd-441a4d565756",
   "metadata": {},
   "source": [
    "we have to create an array of random integers between 1 to 50 with shape (5,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67393a3d-c1ca-4b67-972b-4ab9d7b9e232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41 15 26 24]\n",
      " [23 32 35 16]\n",
      " [35 47 15 28]\n",
      " [21 40 49 10]\n",
      " [50 10 11  4]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "arr=np.random.randint(1,51,size=(5,4))\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31a7e6-4014-4772-80e5-ee5a6554a993",
   "metadata": {},
   "source": [
    "now we have to extract the elements along anti diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "057501b0-49b6-4823-bfe1-45cf6fdd20c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "35\n",
      "47\n",
      "21\n"
     ]
    }
   ],
   "source": [
    " for i in range(min(arr.shape)):\n",
    "     print(arr[i,-1-i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeea38b-d715-4e5a-8ce3-86afbaa5c0cc",
   "metadata": {},
   "source": [
    "now we have to compute and print the max value in each row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8fbd740-0fca-4566-976b-4455916238ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum value of each row is : [41 35 47 49 50]\n"
     ]
    }
   ],
   "source": [
    "max_val=np.max(arr,axis=1)\n",
    "print('maximum value of each row is :',max_val)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2d9ba9-acef-49b3-9c34-755d6dc13627",
   "metadata": {},
   "source": [
    "we have to create a array less than or equal to the mean of the original array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67922154-2a2e-43b5-b7db-d4373a520fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean : 26.6\n"
     ]
    }
   ],
   "source": [
    "print('Mean :',np.mean(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e69ceb7-835b-4904-a6c5-0a51d0596ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15 26 24 23 16 15 21 10 10 11  4]\n"
     ]
    }
   ],
   "source": [
    "filteredarr=arr[arr<=27.55]\n",
    "print(filteredarr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5905b9-3b7e-4d79-8d9b-c26541e8895a",
   "metadata": {},
   "source": [
    "we have to write a boundary traversal function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a10f5f2c-7bfe-45d8-8d00-4b30174266b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function that travels on the boundary of a given matrix\n",
    "def numpy_boundary_traversal(matrix):\n",
    "    top=matrix[0,:]\n",
    "    right=matrix[1:-1,-1]\n",
    "    bottom=matrix[-1,::-1]\n",
    "    left=matrix[-2:0:-1,0]\n",
    "    return np.concatenate([top.flatten(),right.flatten(),bottom.flatten(),left.flatten()])\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fcb032a-fcbc-4094-9728-a4f4cac6d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix=[[46 ,20, 36, 38],\n",
    " [27 ,35 ,34, 28],\n",
    " [ 6 ,36, 17 ,21],\n",
    " [40, 44, 43 , 7],\n",
    " [39 ,20,  3, 11]]\n",
    "matrix=np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45a704af-2ba5-47d3-9b2b-60064baaaf5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46, 20, 36, 38, 28, 21,  7, 11,  3, 20, 39, 40,  6, 27])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_boundary_traversal(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05f16d-cffd-4022-91ea-fb9770b7f326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b30056ae-b69d-435a-bdc2-03b5a26a7952",
   "metadata": {},
   "source": [
    "# question 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b306711-53aa-46b0-9995-90d3ca1dc343",
   "metadata": {},
   "source": [
    "Create a 1-dimensional NumPy array of 20 random floats between 0 and 10. Perform the following tasks:\n",
    "- Print the array and round all elements to two decimal places.\n",
    "- Calculate and print the minimum, maximum, and median of the array.\n",
    "- Replace all elements less than 5 with their squares.\n",
    "- Write a Python function numpy_alternate_sort(array) that takes a 1D NumPy array and returns a new array with elements sorted in an alternating pattern (smallest, largest, second smallest, second largest, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c46a70cf-84e5-445c-8a93-f22453aa6972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4f78681-a283-40f2-82fe-00e0a6a82bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=np.random.uniform(0,10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fbf2e6b-372b-414d-83e8-3987bd433dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array is : [4.07669835 6.92532939 7.52387017 6.89582167 9.6256205  4.39683374\n",
      " 3.8725139  4.77479981 8.88419711 3.45562817 8.32402538 9.68099594\n",
      " 3.96371468 1.26423215 9.71182469 2.09480284 2.89200616 4.58432759\n",
      " 1.22540819 9.25547691]\n"
     ]
    }
   ],
   "source": [
    "print('array is :',arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa938a6c-2b9b-4c73-bbaf-f86e41bcba22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rounded array is : [4.08 6.93 7.52 6.9  9.63 4.4  3.87 4.77 8.88 3.46 8.32 9.68 3.96 1.26\n",
      " 9.71 2.09 2.89 4.58 1.23 9.26]\n"
     ]
    }
   ],
   "source": [
    "# round the array to two decimal places\n",
    "round_arr=np.round(arr,2)\n",
    "print ('Rounded array is :',round_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "153c1cc4-4981-4121-87a6-61bb800aa818",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum=np.min(arr)\n",
    "maximum=np.max(arr)\n",
    "median=np.median(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49497072-d1d7-4bbe-a8d0-b40d3e47aa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum is : 1.2254081863466249\n",
      "Maximum is : 9.711824686755852\n",
      "Median is : 4.679563698914157\n"
     ]
    }
   ],
   "source": [
    "print('Minimum is :',minimum)\n",
    "print('Maximum is :',maximum)\n",
    "print('Median is :',median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "476ccc39-12b7-4e15-967c-7bd120083d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced array is : [16.6194694   6.92532939  7.52387017  6.89582167  9.6256205  19.33214693\n",
      " 14.9963639  22.79871321  8.88419711 11.94136604  8.32402538  9.68099594\n",
      " 15.71103408  1.59828292  9.71182469  4.38819895  8.36369961 21.01605945\n",
      "  1.50162522  9.25547691]\n"
     ]
    }
   ],
   "source": [
    "#replace the numbers which are less than 5 with their squares\n",
    "arrrep = arr.copy() \n",
    "arrrep[arr<5]=arr[arr<5]**2\n",
    "print('Replaced array is :',arrrep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e959e917-3873-4712-90db-c90ccd3f1785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to sort alternatively\n",
    "def numpy_alternate_sort(array):\n",
    "    sorted_arr=np.sort(array)\n",
    "    result=np.zeros_like(array)\n",
    "    n=len(array)\n",
    "    for i in range(n):\n",
    "        if i%2==0:\n",
    "            result[i]=sorted_arr[i//2]\n",
    "        else:\n",
    "            result[i]=sorted_arr[n-(i//2)-1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e451680-73d4-432a-9364-6e69cdc6cf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.65, 9.45, 3.04, 9.21, 3.5 , 8.85, 4.25, 8.68, 4.42, 8.19, 4.42,\n",
       "       8.11, 4.77, 7.16, 4.86, 6.8 , 5.48, 6.36, 5.94, 6.33])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array=[4.86, 4.42 ,9.21 ,8.11, 4.25 ,6.8,  3.04 ,5.48, 8.68 ,5.94, 7.16 ,8.19 ,8.85, 9.45,\n",
    " 3.5 , 2.65, 6.36 ,4.77, 6.33 ,4.42]\n",
    "numpy_alternate_sort(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6d294f-f71b-4c09-b777-34322a23c540",
   "metadata": {},
   "source": [
    "# question 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed30557f-0c9e-4204-a1d9-4e9b798ba7cf",
   "metadata": {},
   "source": [
    "Create a Pandas DataFrame with 10 rows representing student records, with columns Name, Subject, Score (random integers between 50 and 100), and Grade (initially empty). Perform the following tasks:\n",
    "- Assign grades based on scores: A (90–100), B (80–89), C (70–79), D (60–69), F (below 60).\n",
    "- Print the DataFrame sorted by Score in descending order.\n",
    "- Calculate and print the average score for each subject.\n",
    "- Write a Python function pandas_filter_pass(dataframe) that takes a DataFrame and returns a new DataFrame containing only the records with grades A or B.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3688e724-a909-45be-af83-6dc742e52106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9937569-f847-4fa1-8004-3ee81d47ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the required dataframe\n",
    "names = ['Alice', 'Bob', 'Charlie', 'David', 'Emma', 'Frank', 'Grace', 'Hannah', 'Ian', 'Julia']\n",
    "subjects = ['Math', 'Science', 'English', 'History', 'Physics', 'Chemistry', 'Biology', 'Art', 'Music', 'Geography']\n",
    "df = pd.DataFrame({\n",
    "    'Name': names,\n",
    "    'Subject': subjects,\n",
    "    'Score': np.random.randint(50, 101, size=10),  # Random integers between 50 and 100\n",
    "    'Grade': ''  # Initially empty\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d7f1ac4-27cf-4bea-9a07-8735cf38d5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name    Subject  Score Grade\n",
      "0    Alice       Math     63     D\n",
      "1      Bob    Science     61     D\n",
      "2  Charlie    English     54     F\n",
      "3    David    History     68     D\n",
      "4     Emma    Physics     73     C\n",
      "5    Frank  Chemistry     96     A\n",
      "6    Grace    Biology     95     A\n",
      "7   Hannah        Art     81     B\n",
      "8      Ian      Music     90     A\n",
      "9    Julia  Geography     89     B\n"
     ]
    }
   ],
   "source": [
    "# create a function assign grade \n",
    "def assign_grade(score):\n",
    "    if score >= 90:\n",
    "        return 'A'\n",
    "    elif score >= 80:\n",
    "        return 'B'\n",
    "    elif score >= 70:\n",
    "        return 'C'\n",
    "    elif score >= 60:\n",
    "        return 'D'\n",
    "    else:\n",
    "        return 'F'\n",
    "\n",
    "df['Grade'] = df['Score'].apply(assign_grade)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b973d58b-9aab-4eec-8a13-e5b4e959e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted=df.sort_values('Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2386bb86-df9b-475d-b597-5a81518320e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name    Subject  Score Grade\n",
      "2  Charlie    English     54     F\n",
      "1      Bob    Science     61     D\n",
      "0    Alice       Math     63     D\n",
      "3    David    History     68     D\n",
      "4     Emma    Physics     73     C\n",
      "7   Hannah        Art     81     B\n",
      "9    Julia  Geography     89     B\n",
      "8      Ian      Music     90     A\n",
      "6    Grace    Biology     95     A\n",
      "5    Frank  Chemistry     96     A\n"
     ]
    }
   ],
   "source": [
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e2abb64-ac84-44c7-a5e3-031364e1832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping the scores of same subject\n",
    "average_by_subject = df.groupby('Subject')['Score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41f47770-3446-4241-8a5f-8837b4152bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject\n",
      "Art          81.0\n",
      "Biology      95.0\n",
      "Chemistry    96.0\n",
      "English      54.0\n",
      "Geography    89.0\n",
      "History      68.0\n",
      "Math         63.0\n",
      "Music        90.0\n",
      "Physics      73.0\n",
      "Science      61.0\n",
      "Name: Score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(average_by_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec329c50-0a4e-461d-9e9d-38a48141c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a filter pass function that has dataframe only with grade A or B\n",
    "def pandas_filter_pass(dataframe) :\n",
    "    df_filt=dataframe[dataframe['Grade'].isin(['A', 'B'])]\n",
    "    return df_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa6f1024-67f7-40e6-89ca-9c0b23cbc545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Score</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Frank</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>96</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Grace</td>\n",
       "      <td>Biology</td>\n",
       "      <td>95</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hannah</td>\n",
       "      <td>Art</td>\n",
       "      <td>81</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ian</td>\n",
       "      <td>Music</td>\n",
       "      <td>90</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Julia</td>\n",
       "      <td>Geography</td>\n",
       "      <td>89</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name    Subject  Score Grade\n",
       "5   Frank  Chemistry     96     A\n",
       "6   Grace    Biology     95     A\n",
       "7  Hannah        Art     81     B\n",
       "8     Ian      Music     90     A\n",
       "9   Julia  Geography     89     B"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_filter_pass(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f38f652-28ec-4eeb-9476-5346a01b73f8",
   "metadata": {},
   "source": [
    "# question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91a7ef6-d4c7-4e1f-a823-98dfd7267647",
   "metadata": {},
   "source": [
    "Create a synthetic dataset which is a list of 100 short movie reviews (50 positive, 50 negative) stored in a Pandas DataFrame with columns Review (text) and Sentiment (positive/negative). Perform the following tasks:\n",
    "\n",
    "- Tokenize the reviews using CountVectorizer with a maximum of 500 features, removing stop words.\n",
    "- Split the dataset into training (80%) and testing (20%) sets using train_test_split.\n",
    "- Train a Multinomial Naive Bayes classifier on the tokenized training data and print the accuracy on the test set.\n",
    "- Write a Python function predict_review_sentiment(model, vectorizer, review) that takes a trained model, the fitted CountVectorizer, and a single review (string), and returns the predicted sentiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "787a5b0a-16e3-4c35-b4eb-038228dafe09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (100, 2)\n",
      "\n",
      "Sample reviews:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I found it terrible acting. Such a mediocre mo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie had well directed. Fantastic experi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A terrible movie with weak characters.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I beautifully shot. It was a fantastic film.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I excellent plot. It was a delightful film.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I worth watching. It was a brilliant film.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I powerful soundtrack. It was a superb film.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This film was fell asleep. Disappointing exper...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I incredible acting. It was a excellent film.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Terrible acting. I would not recommend this ho...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Sentiment\n",
       "0  I found it terrible acting. Such a mediocre mo...  negative\n",
       "1  This movie had well directed. Fantastic experi...  positive\n",
       "2             A terrible movie with weak characters.  negative\n",
       "3       I beautifully shot. It was a fantastic film.  positive\n",
       "4        I excellent plot. It was a delightful film.  positive\n",
       "5         I worth watching. It was a brilliant film.  positive\n",
       "6       I powerful soundtrack. It was a superb film.  positive\n",
       "7  This film was fell asleep. Disappointing exper...  negative\n",
       "8      I incredible acting. It was a excellent film.  positive\n",
       "9  Terrible acting. I would not recommend this ho...  negative"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Create lists of positive and negative phrases to build reviews\n",
    "positive_phrases = [\n",
    "    \"loved the movie\", \"brilliant performance\", \"outstanding cinematography\", \n",
    "    \"excellent plot\", \"well directed\", \"captivating story\", \"amazing visual effects\",\n",
    "    \"great character development\", \"powerful soundtrack\", \"emotional journey\",\n",
    "    \"masterpiece\", \"worth watching\", \"incredible acting\", \"beautifully shot\",\n",
    "    \"engaging from start to finish\"\n",
    "]\n",
    "\n",
    "negative_phrases = [\n",
    "    \"waste of time\", \"terrible acting\", \"poor direction\", \"boring plot\",\n",
    "    \"predictable storyline\", \"disappointing ending\", \"awful dialogue\",\n",
    "    \"poorly executed\", \"weak characters\", \"bad pacing\", \"confusing narrative\",\n",
    "    \"overrated\", \"fell asleep\", \"not worth the money\", \"forgettable\"\n",
    "]\n",
    "\n",
    "# Additional adjectives to add variety\n",
    "positive_adj = [\"amazing\", \"fantastic\", \"excellent\", \"superb\", \"wonderful\", \"brilliant\", \"delightful\"]\n",
    "negative_adj = [\"terrible\", \"awful\", \"horrible\", \"disappointing\", \"dreadful\", \"mediocre\", \"poor\"]\n",
    "\n",
    "# Generate 50 positive reviews\n",
    "positive_reviews = []\n",
    "for _ in range(50):\n",
    "    base = random.choice(positive_phrases)\n",
    "    adj = random.choice(positive_adj)\n",
    "    \n",
    "    # Create different review structures for variety\n",
    "    structure = random.randint(1, 4)\n",
    "    if structure == 1:\n",
    "        review = f\"I {base}. It was a {adj} film.\"\n",
    "    elif structure == 2:\n",
    "        review = f\"This movie had {base}. {adj.capitalize()} experience overall.\"\n",
    "    elif structure == 3:\n",
    "        review = f\"A {adj} film with {base}.\"\n",
    "    else:\n",
    "        review = f\"{base.capitalize()}! I would definitely recommend this {adj} movie.\"\n",
    "    \n",
    "    positive_reviews.append(review)\n",
    "\n",
    "# Generate 50 negative reviews\n",
    "negative_reviews = []\n",
    "for _ in range(50):\n",
    "    base = random.choice(negative_phrases)\n",
    "    adj = random.choice(negative_adj)\n",
    "    \n",
    "    # Create different review structures for variety\n",
    "    structure = random.randint(1, 4)\n",
    "    if structure == 1:\n",
    "        review = f\"I found it {base}. Such a {adj} movie.\"\n",
    "    elif structure == 2:\n",
    "        review = f\"This film was {base}. {adj.capitalize()} experience overall.\"\n",
    "    elif structure == 3:\n",
    "        review = f\"A {adj} movie with {base}.\"\n",
    "    else:\n",
    "        review = f\"{base.capitalize()}. I would not recommend this {adj} film.\"\n",
    "    \n",
    "    negative_reviews.append(review)\n",
    "\n",
    "# Create DataFrame\n",
    "reviews = positive_reviews + negative_reviews\n",
    "sentiments = ['positive'] * 50 + ['negative'] * 50\n",
    "\n",
    "# Shuffle the data while keeping reviews and sentiments aligned\n",
    "combined = list(zip(reviews, sentiments))\n",
    "random.shuffle(combined)\n",
    "reviews, sentiments = zip(*combined)\n",
    "\n",
    "# Create the final DataFrame\n",
    "movie_reviews_df = pd.DataFrame({\n",
    "    'Review': reviews,\n",
    "    'Sentiment': sentiments\n",
    "})\n",
    "\n",
    "# Display the first few rows\n",
    "print(f\"Dataset shape: {movie_reviews_df.shape}\")\n",
    "print(\"\\nSample reviews:\")\n",
    "movie_reviews_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09d76702-7906-4050-960f-6b809366e522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        12\n",
      "    positive       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "\n",
      "Prediction Examples:\n",
      "Review: 'This movie was fantastic! I loved every minute of it.'\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Review: 'What a waste of time. The acting was terrible and the plot made no sense.'\n",
      "Predicted sentiment: negative\n",
      "\n",
      "Review: 'I'm not sure how I feel about this film. It had good and bad moments.'\n",
      "Predicted sentiment: negative\n",
      "\n",
      "\n",
      "Most Informative Features:\n",
      "\n",
      "Top 10 features for class 'negative':\n",
      "terrible, characters, mediocre, experience, overall, awful, poor, recommend, film, movie\n",
      "\n",
      "Top 10 features for class 'positive':\n",
      "superb, acting, definitely, recommend, overall, experience, brilliant, excellent, movie, film\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming movie_reviews_df is already created from the previous code\n",
    "\n",
    "# Step 1: Tokenize the reviews using CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=500, stop_words='english')\n",
    "X = vectorizer.fit_transform(movie_reviews_df['Review'])\n",
    "y = movie_reviews_df['Sentiment']\n",
    "\n",
    "# Step 2: Split the dataset into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train a Multinomial Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 4: Create the prediction function\n",
    "def predict_review_sentiment(model, vectorizer, review):\n",
    "    \"\"\"\n",
    "    Predicts the sentiment of a single movie review.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : trained classifier model\n",
    "        The trained machine learning model\n",
    "    vectorizer : CountVectorizer\n",
    "        The fitted CountVectorizer used to transform text\n",
    "    review : str\n",
    "        The movie review text to classify\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        The predicted sentiment ('positive' or 'negative')\n",
    "    \"\"\"\n",
    "    # Transform the review text using the same vectorizer\n",
    "    review_vectorized = vectorizer.transform([review])\n",
    "    \n",
    "    # Predict the sentiment\n",
    "    prediction = model.predict(review_vectorized)[0]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# Demonstrate the function with a few examples\n",
    "example_reviews = [\n",
    "    \"This movie was fantastic! I loved every minute of it.\",\n",
    "    \"What a waste of time. The acting was terrible and the plot made no sense.\",\n",
    "    \"I'm not sure how I feel about this film. It had good and bad moments.\"\n",
    "]\n",
    "\n",
    "print(\"\\nPrediction Examples:\")\n",
    "for review in example_reviews:\n",
    "    sentiment = predict_review_sentiment(nb_classifier, vectorizer, review)\n",
    "    print(f\"Review: '{review}'\")\n",
    "    print(f\"Predicted sentiment: {sentiment}\\n\")\n",
    "\n",
    "# Show the most informative features (words) for each class\n",
    "def display_most_informative_features(vectorizer, classifier, n=10):\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    class_labels = classifier.classes_\n",
    "    \n",
    "    # For each class, find the most important features\n",
    "    for i, label in enumerate(class_labels):\n",
    "        top_indices = np.argsort(classifier.feature_log_prob_[i])[-n:]\n",
    "        top_features = [feature_names[j] for j in top_indices]\n",
    "        print(f\"\\nTop {n} features for class '{label}':\")\n",
    "        print(\", \".join(top_features))\n",
    "\n",
    "print(\"\\nMost Informative Features:\")\n",
    "display_most_informative_features(vectorizer, nb_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5aa82c13-c970-4089-b717-ce6285f36766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming movie_reviews_df is already created from the previous code\n",
    "\n",
    "# Step 1: Tokenize the reviews using CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=500, stop_words='english')\n",
    "X = vectorizer.fit_transform(movie_reviews_df['Review'])\n",
    "y = movie_reviews_df['Sentiment']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf47a59-1543-411f-818d-cd02ebd45f39",
   "metadata": {},
   "source": [
    "Step 2: Split the dataset into training (80%) and testing (20%) sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02e7cbc3-a857-4cf4-9fc5-9f991961d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc28b67a-f37d-40f3-a5a3-9fafea806778",
   "metadata": {},
   "source": [
    "Step 3: Train a Multinomial Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8999447-4121-4f37-84c8-eea111fc0428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        12\n",
      "    positive       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1f700f-a6d6-4b49-ba11-7b6d40d5504d",
   "metadata": {},
   "source": [
    "# Step 4: Create the prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "013cfa37-8b57-42e3-aeee-6fd72f50db48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Examples:\n",
      "Review: 'This movie was fantastic! I loved every minute of it.'\n",
      "Predicted sentiment: positive\n",
      "\n",
      "Review: 'What a waste of time. The acting was terrible and the plot made no sense.'\n",
      "Predicted sentiment: negative\n",
      "\n",
      "Review: 'I'm not sure how I feel about this film. It had good and bad moments.'\n",
      "Predicted sentiment: negative\n",
      "\n",
      "\n",
      "Most Informative Features:\n",
      "\n",
      "Top 10 features for class 'negative':\n",
      "terrible, characters, mediocre, experience, overall, awful, poor, recommend, film, movie\n",
      "\n",
      "Top 10 features for class 'positive':\n",
      "superb, acting, definitely, recommend, overall, experience, brilliant, excellent, movie, film\n"
     ]
    }
   ],
   "source": [
    "def predict_review_sentiment(model, vectorizer, review):\n",
    "    \"\"\"\n",
    "    Predicts the sentiment of a single movie review.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : trained classifier model\n",
    "        The trained machine learning model\n",
    "    vectorizer : CountVectorizer\n",
    "        The fitted CountVectorizer used to transform text\n",
    "    review : str\n",
    "        The movie review text to classify\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        The predicted sentiment ('positive' or 'negative')\n",
    "    \"\"\"\n",
    "    # Transform the review text using the same vectorizer\n",
    "    review_vectorized = vectorizer.transform([review])\n",
    "    \n",
    "    # Predict the sentiment\n",
    "    prediction = model.predict(review_vectorized)[0]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# Demonstrate the function with a few examples\n",
    "example_reviews = [\n",
    "    \"This movie was fantastic! I loved every minute of it.\",\n",
    "    \"What a waste of time. The acting was terrible and the plot made no sense.\",\n",
    "    \"I'm not sure how I feel about this film. It had good and bad moments.\"\n",
    "    ]\n",
    "\n",
    "print(\"\\nPrediction Examples:\")\n",
    "for review in example_reviews:\n",
    "    sentiment = predict_review_sentiment(nb_classifier, vectorizer, review)\n",
    "    print(f\"Review: '{review}'\")\n",
    "    print(f\"Predicted sentiment: {sentiment}\\n\")\n",
    "\n",
    "# Show the most informative features (words) for each class\n",
    "def display_most_informative_features(vectorizer, classifier, n=10):\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    class_labels = classifier.classes_\n",
    "    \n",
    "    # For each class, find the most important features\n",
    "    for i, label in enumerate(class_labels):\n",
    "        top_indices = np.argsort(classifier.feature_log_prob_[i])[-n:]\n",
    "        top_features = [feature_names[j] for j in top_indices]\n",
    "        print(f\"\\nTop {n} features for class '{label}':\")\n",
    "        print(\", \".join(top_features))\n",
    "\n",
    "print(\"\\nMost Informative Features:\")\n",
    "display_most_informative_features(vectorizer, nb_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c4ccb3-8a6f-4195-b580-659c6ba86375",
   "metadata": {},
   "source": [
    "Question 5\n",
    "\n",
    "Create a synthetic dataset of 100 short text samples (e.g., product feedback) with binary labels (good/bad) and apply an NLP pipeline using scikit-learn. Perform the following tasks:\n",
    "\n",
    "Preprocess the text using TfidfVectorizer with a maximum of 300 features, applying lowercasing and stop word removal.\n",
    "\n",
    "Split the dataset into training (75%) and testing (25%) sets.\n",
    "\n",
    "Train a Logistic Regression model on the vectorized training data and print the precision, recall, and F1-score for the test set.\n",
    "\n",
    "Write a Python function text_preprocess_vectorize(texts, vectorizer) that takes a list of text samples and a fitted TfidfVectorizer, and returns the vectorized feature matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44fdf05a-cf8e-4323-a7e4-3a68c6979899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Create synthetic dataset of 100 short text samples with binary labels\n",
    "positive_phrases = [\n",
    "    \"excellent product\", \"works great\", \"highly recommend\", \"very satisfied\",\n",
    "    \"good quality\", \"amazing service\", \"fast delivery\", \"perfect fit\",\n",
    "    \"easy to use\", \"worth the money\", \"exceeded expectations\", \"very durable\",\n",
    "    \"fantastic customer support\", \"best purchase ever\", \"love it\"\n",
    "]\n",
    "\n",
    "negative_phrases = [\n",
    "    \"poor quality\", \"doesn't work\", \"waste of money\", \"very disappointed\",\n",
    "    \"broke easily\", \"terrible service\", \"slow delivery\", \"doesn't fit\",\n",
    "    \"difficult to use\", \"overpriced\", \"below expectations\", \"not durable\",\n",
    "    \"no customer support\", \"worst purchase ever\", \"hate it\"\n",
    "]\n",
    "\n",
    "# Generate synthetic reviews\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "for _ in range(50):  # 50 positive reviews\n",
    "    base = random.choice(positive_phrases)\n",
    "    extra_words = random.randint(0, 5)\n",
    "    extra = \" \".join(random.choice(positive_phrases).split()[:extra_words])\n",
    "    texts.append(f\"{base} {extra}\".strip())\n",
    "    labels.append(1)  # 1 for positive\n",
    "\n",
    "for _ in range(50):  # 50 negative reviews\n",
    "    base = random.choice(negative_phrases)\n",
    "    extra_words = random.randint(0, 5)\n",
    "    extra = \" \".join(random.choice(negative_phrases).split()[:extra_words])\n",
    "    texts.append(f\"{base} {extra}\".strip())\n",
    "    labels.append(0)  # 0 for negative\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "df = pd.DataFrame({'text': texts, 'label': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57d7f20d-dd7f-4783-aea6-eb115594794c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exceeded expectations</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>very durable very satisfied</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>very satisfied very</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>works great very durable</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love it works great</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>doesn't work below expectations</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>poor quality doesn't</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>hate it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>terrible service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>very disappointed below expectations</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    text  label\n",
       "0                  exceeded expectations      1\n",
       "1            very durable very satisfied      1\n",
       "2                    very satisfied very      1\n",
       "3               works great very durable      1\n",
       "4                    love it works great      1\n",
       "..                                   ...    ...\n",
       "95       doesn't work below expectations      0\n",
       "96                  poor quality doesn't      0\n",
       "97                               hate it      0\n",
       "98                      terrible service      0\n",
       "99  very disappointed below expectations      0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "513fcb39-baa5-426e-9384-6965124e77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46dd5b09-8db0-4f45-b712-3310a8536801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the text preprocessing and vectorization function\n",
    "def text_preprocess_vectorize(texts, vectorizer):\n",
    "    return vectorizer.transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48de2f9e-61f1-4a61-8a3d-b92bca754684",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=300,  # Maximum 300 features\n",
    "    stop_words='english',  # Remove English stop words\n",
    "    lowercase=True  # Convert text to lowercase\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75e70550-5828-4883-9c2d-c6acaae8c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the vectorizer on the entire dataset\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "563b5e46-a0ba-479b-b286-8ec728e1e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training (75%) and testing (25%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c19ae4f-d4d8-429a-872a-1dc27069abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b64b490-8315-414d-8d0b-6742b1dbb850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.89      1.00      0.94         8\n",
      "    Positive       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.96        25\n",
      "   macro avg       0.94      0.97      0.96        25\n",
      "weighted avg       0.96      0.96      0.96        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc038a0a-41ad-4202-ab26-87159527df37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions for new texts:\n",
      "Text: 'This product is amazing' - Predicted: Positive\n",
      "Text: 'Terrible experience, don't buy' - Predicted: Negative\n"
     ]
    }
   ],
   "source": [
    "# Example of using the text_preprocess_vectorize function\n",
    "new_texts = [\"This product is amazing\", \"Terrible experience, don't buy\"]\n",
    "new_features = text_preprocess_vectorize(new_texts, vectorizer)\n",
    "new_predictions = model.predict(new_features)\n",
    "print(\"\\nPredictions for new texts:\")\n",
    "for text, pred in zip(new_texts, new_predictions):\n",
    "    sentiment = \"Positive\" if pred == 1 else \"Negative\"\n",
    "    print(f\"Text: '{text}' - Predicted: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ad80b-01f7-486e-9ced-04fcf0a2f906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
